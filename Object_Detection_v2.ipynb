{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"15yUGJBUtyqHdRAxuQVoLeIRyh9HFDAGH","authorship_tag":"ABX9TyON8UweuIrXymu66JRG+t8U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install roboflow"],"metadata":{"id":"03gUiJ_dE-JV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics==8.0.196"],"metadata":{"id":"9ZPSf40-G-yi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","import os\n","import torch\n","import torchvision\n","from torch import nn"],"metadata":{"id":"_LKUbV6iPkz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# getting our annotated data from roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"FzschU3rcFSGL0KcALsV\")\n","project = rf.workspace(\"caloriescan\").project(\"caloriescan-buf3z\")\n","dataset = project.version(1).download(\"yolov8\")"],"metadata":{"id":"qsjUvJe2HNL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training custom YOLOv8 model\n","from ultralytics import YOLO\n","model = YOLO('yolov8n.pt')\n","model.train(data='CalorieScan-1/data.yaml', epochs=10)"],"metadata":{"id":"9ADRfGYPFBzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"W3ZONmSaHakH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6WO14pzQN6U","executionInfo":{"status":"ok","timestamp":1702568149233,"user_tz":-330,"elapsed":18815,"user":{"displayName":"Spandan Panda","userId":"15859669930948136281"}},"outputId":"ce952012-4f48-4f73-e1c9-edad48859dc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# !rm -rf runs/detect/train"],"metadata":{"id":"iyG6A1SgIBn1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !ls"],"metadata":{"id":"UwZOQh42QrNo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !yolo task=detect mode=predict model='/content/runs/detect/train/weights/best.pt' source='/content/drive/MyDrive/MLPR Project/Data/raw_data/1.jpg' save_txt=True"],"metadata":{"id":"j6oQ2zvTIANV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading the custom trained model's parameters\n","from PIL import Image\n","model = YOLO('/content/runs/detect/train/weights/best.pt')\n","im = Image.open('/content/drive/MyDrive/MLPR Project/Data/raw_data/1.jpg')\n","results = model.predict(source=im, save=True, save_txt=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rsna-BDvw_Yk","executionInfo":{"status":"ok","timestamp":1702583955157,"user_tz":-330,"elapsed":4688,"user":{"displayName":"Spandan Panda","userId":"15859669930948136281"}},"outputId":"5411bf39-e99b-4f96-a9ee-223df43dde41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\n","0: 480x640 6 bowls, 398.4ms\n","Speed: 6.2ms preprocess, 398.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","1 label saved to runs/detect/predict/labels\n"]}]},{"cell_type":"code","source":["# !zip -r '/content/runs2.zip' '/content/runs'"],"metadata":{"id":"mxGnNGSNQNwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the trained model\n","loaded_model = torchvision.models.resnet18(pretrained=False)\n","loaded_model.fc = nn.Linear(loaded_model.fc.in_features, 45)\n","loaded_model.load_state_dict(torch.load('/content/drive/MyDrive/MLPR Project/models/finetune_model_new.pth'))\n","loaded_model.eval()"],"metadata":{"id":"RDu7q2uOOH-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/MLPR Project/Data/cropped\")"],"metadata":{"id":"8zkEw_8tUCdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dataset.classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aL8UJjB0yb9V","executionInfo":{"status":"ok","timestamp":1702568158453,"user_tz":-330,"elapsed":4,"user":{"displayName":"Spandan Panda","userId":"15859669930948136281"}},"outputId":"7c13d89e-a47c-441b-a6d2-6ebae7ef2379"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Aloo_Nutri', 'Bhatura', 'Bhindi', 'Biryani', 'Black_Chana', 'Boondi_Curd', 'Chicken', 'Chocos', 'Chole_Rice', 'Curd', 'Dal', 'Dal_Rice', 'Fruit_Custard', 'Ghiya', 'Gobhi', 'Gulab_Jamun', 'Halwa', 'Honey_Chili_Potato', 'Kadhi', 'Kadhi_Rice', 'Kheer', 'Mix_Veg', 'Mushroom_Matar', 'Noodles', 'Nutri_Masala', 'Paneer', 'Papad', 'Pasta', 'Poori', 'Pumpkin_Sabzi', 'Rajma', 'Rice', 'Roti', 'Salad', 'Semiya_Kheer', 'Shahi_Tukda', 'Tori', 'White_Chana']\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","normalize = torchvision.transforms.Normalize(\n","    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","test_augs = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize([256, 256]),\n","    torchvision.transforms.CenterCrop(224),\n","    torchvision.transforms.ToTensor(),\n","    normalize])"],"metadata":{"id":"U-Xf6PT6QxEH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","from torchvision import transforms\n","\n","def convert_yolo_to_normal(image_width, image_height, bbox):\n","    \"\"\"\n","    Convert YOLO label format to normal bounding box format.\n","    YOLO format: [class_id, x_center, y_center, width, height]\n","    Normal format: [x_min, y_min, x_max, y_max]\n","    \"\"\"\n","    x_center, y_center, width, height = bbox[1:]\n","    x_min = int((x_center - width / 2) * image_width)\n","    y_min = int((y_center - height / 2) * image_height)\n","    x_max = int((x_center + width / 2) * image_width)\n","    y_max = int((y_center + height / 2) * image_height)\n","\n","    return [x_min, y_min, x_max, y_max]\n","\n","def crop_image(image_path, label_path, output_folder, pt=False):\n","    \"\"\"\n","    Crop the part of the image specified by the YOLO-format label.\n","    \"\"\"\n","    # Read the image\n","    image = cv2.imread(image_path)\n","    h, w, _ = image.shape\n","    pred_labels = []\n","\n","    # Read the label file\n","    with open(label_path, 'r') as f:\n","        lines = f.readlines()\n","\n","    for i, line in enumerate(lines):\n","        bbox = list(map(float, line.strip().split()))\n","        bbox_normal = convert_yolo_to_normal(w, h, bbox)\n","\n","        # Crop the image\n","        cropped_image = image[bbox_normal[1]:bbox_normal[3], bbox_normal[0]:bbox_normal[2]]\n","\n","        # Save the cropped image\n","        output_path = os.path.join(output_folder, f\"{os.path.basename(image_path).split('.')[0]}_crop_{i}.jpg\")\n","        cv2.imwrite(output_path, cropped_image)\n","\n","        im = torchvision.io.read_image(output_path)\n","        im = im.float() / 255.0  # Convert to float and normalize to [0, 1]\n","        im = normalize(im)  # Apply normalization\n","        im = im.unsqueeze(0)  # Add batch dimension\n","\n","        # Make prediction\n","        with torch.no_grad():\n","            output = loaded_model(im)\n","\n","        print(torch.argmax(output))\n","\n","        # Get predicted class\n","        predicted_class = torch.argmax(output).item()\n","\n","        # Get label from dataset\n","        label = dataset.classes[predicted_class]\n","        if pt == True:\n","          print(label)\n","        pred_labels.append(label)\n","        os.remove(output_path)\n","\n","        return pred_labels"],"metadata":{"id":"dfecTE_8NcoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crop_image('/content/drive/MyDrive/MLPR Project/Data/raw_data/1.jpg', '/content/runs/detect/predict/labels/1.txt', '/content/', True)"],"metadata":{"id":"cgDS4p9hcAvN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702594275439,"user_tz":-330,"elapsed":15,"user":{"displayName":"Spandan Panda","userId":"15859669930948136281"}},"outputId":"d2326eef-54c8-4f9b-f2d6-d4ffa9a105bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Blank\n","Blank\n","Curd\n","Semiya_Kheer\n","Salad\n","Black_Chana\n"]}]},{"cell_type":"code","source":["cal_dict = {\n","    \"Halwa\": 285,\n","    \"Dal\": 230,\n","    \"Roti\": 297,\n","    \"Rice\": 242,\n","    \"Papad\": 371,\n","    \"Mushroom_Matar\": 173,\n","    \"Chana_Salad\": 195,\n","    \"Dal_Rice\": 293,\n","    \"Mix_Veg\": 162,\n","    \"Kheer\": 235,\n","    \"Thepla\": 120,\n","    \"Green_Chutney\": \"40\",\n","    \"Chocos\": 111,\n","    \"Curd\": 59,\n","    \"Paneer\": 265,\n","    \"Semiya_Kheer\": 249,\n","    \"Black_Chana\": 378,\n","    \"Bhindi\": 33,\n","    \"Salad\": 30,\n","    \"Chole Rice\": 300,\n","    \"Chicken\": 200,\n","    \"Nutri_Masala\": 150,\n","    \"White_Chana\": 180,\n","    \"Boondi_Curd\": 250,\n","     \"Noodles\": 300,\n","    \"Fruit_Custard\": 200,\n","    \"Honey_Chili_Potato\": 350,\n","    \"Ghiya\": 100,\n","    \"Rajma\": 200,\n","    \"Gulab_Jamun\": 250,\n","    \"Shahi_Tukda\": 400,\n","    \"Aloo_Nutri\": 250,\n","    \"Bhatura\": 300,\n","    \"Biryani\": 500,\n","    \"Gobhi\": 150,\n","    \"Pasta\": 350,\n","    \"Pumpkin_Sabzi\": 150,\n","    \"Poori\": 250,\n","    \"Tori\": 180,\n","    \"Kadhi\": 250,\n","    \"Kadhi_Rice\": 400,\n","    \"Aloo_Gobhi\": 200,\n","    \"Fried_Rice\": 350,\n","    \"Aloo_Methi\": 200,\n","    \"Rajma_Rice\": 450\n","}"],"metadata":{"id":"0nSGZ7KwglSM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","import random\n","\n","correct = 0\n","all = 0\n","\n","def get_labels(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    labels = []\n","    for obj in root.iter('object'):\n","        label = obj.find('name').text\n","        labels.append(label)\n","    return labels\n","\n","for i in range(30):\n","    cal = 0\n","    j = random.randint(1, 270)\n","    # model = YOLO('/content/runs/detect/train/weights/best.pt')\n","    im = Image.open('/content/drive/MyDrive/MLPR Project/Data/raw_data/1.jpg')\n","    results = model.predict(source=im, save=True, save_txt=True)\n","    pred_labels = crop_image(f'/content/drive/MyDrive/MLPR Project/Data/raw_data/{j}.jpg', f'/content/runs/detect/predict/labels/{j}.txt', '/content/')\n","    actual_labels = get_labels(f'/content/drive/MyDrive/MLPR Project/Data/labels_mlpr/{j}.jpg')\n","    for k in pred_labels:\n","      cal += cal_dict[k]\n","    correct += len(set(pred_labels).intersection(actual_labels))\n","    all += len(set(pred_labels))\n","\n","print(\"Accuracy is\", correct/all)"],"metadata":{"id":"nWd7Dnxez5u4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702594596208,"user_tz":-330,"elapsed":452,"user":{"displayName":"Spandan Panda","userId":"15859669930948136281"}},"outputId":"c27dd10a-2ca2-41a0-a70f-91d6483e4fbf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy is 78.68\n"]}]}]}